import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,f as n,o as i}from"./app-CfLacg5d.js";const t={};function r(p,a){return i(),e("div",null,[...a[0]||(a[0]=[n(`<h1 id="fastapi-langgraphæ­å»º-ai-å·¥ä½œæµ" tabindex="-1"><a class="header-anchor" href="#fastapi-langgraphæ­å»º-ai-å·¥ä½œæµ"><span>FastAPI + LangGraphæ­å»º AI å·¥ä½œæµ</span></a></h1><p>AIå¤§æ¨¡å‹è§‚å¯Ÿç«™**<br><a href="https://mp.weixin.qq.com/s?__biz=MzkzMjkwMjk3Mw%3D%3D&amp;mid=2247485621&amp;idx=1&amp;sn=5a3207f4b0e2876800b74cda5c3683df" target="_blank" rel="noopener noreferrer"><strong>æŸ¥çœ‹åŸæ–‡</strong></a></p><h2 id="ä½œè€…-aiç ”ç©¶ç”Ÿ" tabindex="-1"><a class="header-anchor" href="#ä½œè€…-aiç ”ç©¶ç”Ÿ"><span>ä½œè€… AIç ”ç©¶ç”Ÿ</span></a></h2><p>AIå¤§æ¨¡å‹è§‚å¯Ÿç«™</p><p><strong>Large Language Models (LLMs)</strong>Â æ“…é•¿æ¨ç†ï¼Œä½†ç°å®ä¸–ç•Œçš„åº”ç”¨å¾€å¾€éœ€è¦æœ‰çŠ¶æ€ã€å¤šæ­¥éª¤çš„å·¥ä½œæµã€‚è¿™å°±æ˜¯Â <strong>LangGraph</strong>Â çš„ç”¨æ­¦ä¹‹åœ°â€”â€”å®ƒè®©ä½ å¯ä»¥é€šè¿‡ç”± LLM é©±åŠ¨çš„èŠ‚ç‚¹å›¾æ¥æ„å»ºæ™ºèƒ½å·¥ä½œæµã€‚</p><figure><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/6Ex6Atic0gTyjGMgfE14oc2TGne0Vj2ibZQK9udtCtZDlo9JB2iaU81DNXJicyjWMbNHibmH2PxFPz6ya53GnB5hyTA/640?wx_fmt=webp&amp;from=appmsg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>ä½†å¦‚æœä½ æƒ³æŠŠè¿™äº›å·¥ä½œæµæš´éœ²ä¸ºÂ <strong>APIs</strong>ï¼Œè®©å…¶ä»–åº”ç”¨ï¼ˆæˆ–ç”¨æˆ·ï¼‰å¯ä»¥è°ƒç”¨å‘¢ï¼Ÿè¿™æ—¶å€™Â <strong>FastAPI</strong>Â å°±æ´¾ä¸Šç”¨åœºäº†â€”â€”ä¸€ä¸ªè½»é‡çº§ã€é«˜æ€§èƒ½çš„ Python Web æ¡†æ¶ã€‚</p><p>åœ¨è¿™ç¯‡æŒ‡å—ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•å°†Â <strong>LangGraph</strong>Â å·¥ä½œæµå°è£…åœ¨Â <strong>FastAPI</strong>Â ä¸­ï¼Œå˜æˆä¸€ä¸ªç”Ÿäº§å°±ç»ªçš„Â <strong>endpoint</strong>ã€‚</p><h3 id="ä¸ºä»€ä¹ˆé€‰æ‹©-langgraph-fastapi" tabindex="-1"><a class="header-anchor" href="#ä¸ºä»€ä¹ˆé€‰æ‹©-langgraph-fastapi"><span>ä¸ºä»€ä¹ˆé€‰æ‹© LangGraph + FastAPIï¼Ÿ</span></a></h3><ul><li>â€¢Â <strong>LangGraph</strong>ï¼šåˆ›å»ºå¤šæ­¥éª¤ã€æœ‰çŠ¶æ€çš„ LLM å·¥ä½œæµï¼ˆä¾‹å¦‚ï¼Œå¤šæ™ºèƒ½ä½“æ¨ç†ã€æ•°æ®å¤„ç†ï¼‰ã€‚</li><li>â€¢Â <strong>FastAPI</strong>ï¼šè½»æ¾å°†è¿™äº›å·¥ä½œæµæš´éœ²ä¸ºÂ <strong>REST APIs</strong>ï¼Œä»¥ä¾¿ä¸ Web åº”ç”¨ã€å¾®æœåŠ¡æˆ–è‡ªåŠ¨åŒ–æµæ°´çº¿é›†æˆã€‚</li><li>â€¢Â <strong>ç»“åˆä¸¤è€…</strong>ï¼šæ„å»ºå¯ä»ä»»ä½•åœ°æ–¹è®¿é—®çš„å¯æ‰©å±• AI æ™ºèƒ½ä½“ã€‚</li></ul><h3 id="_1-é¡¹ç›®è®¾ç½®" tabindex="-1"><a class="header-anchor" href="#_1-é¡¹ç›®è®¾ç½®"><span>1. é¡¹ç›®è®¾ç½®</span></a></h3><p>åˆ›å»ºä¸€ä¸ªæ–°é¡¹ç›®æ–‡ä»¶å¤¹å¹¶å®‰è£…ä¾èµ–ï¼š</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span>mkdir langgraph_fastapi_demo &amp;&amp; cd langgraph_fastapi_demopython -m venv .venvsource .venv/bin/activate  </span></span>
<span class="line"><span># åœ¨ Windows ä¸Šï¼š.venv\\Scripts\\activatepip install fastapi uvicorn langgraph langchain-openai python-dotenv</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>åˆ›å»ºä¸€ä¸ªÂ <code>.env</code>Â æ–‡ä»¶æ¥å­˜å‚¨ä½ çš„ API å¯†é’¥ï¼š</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span>OPENAI_API_KEY=ä½ çš„_openai_å¯†é’¥_åœ¨æ­¤</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="_2-æ„å»ºä¸€ä¸ªç®€å•çš„-langgraph-å·¥ä½œæµ" tabindex="-1"><a class="header-anchor" href="#_2-æ„å»ºä¸€ä¸ªç®€å•çš„-langgraph-å·¥ä½œæµ"><span>2. æ„å»ºä¸€ä¸ªç®€å•çš„ LangGraph å·¥ä½œæµ</span></a></h3><p>è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªç®€å•çš„Â <strong>LangGraph</strong>ï¼Œå®ƒæ¥æ”¶ç”¨æˆ·çš„é—®é¢˜å¹¶è¿”å› AI ç”Ÿæˆçš„ç­”æ¡ˆã€‚</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span># workflow.pyfrom langgraph.graph import StateGraph, START, ENDfrom langchain_openai import ChatOpenAIfrom langchain_core.messages import HumanMessageimport osfrom dotenv import load_dotenvload_dotenv()llm = ChatOpenAI(model=&quot;gpt-4o&quot;)  # å¯ä»¥åˆ‡æ¢åˆ° gpt-4o-mini ä»¥é™ä½æˆæœ¬# å®šä¹‰çŠ¶æ€defanswer_question(state: dict) -&gt; dict:    user_input = state[&quot;user_input&quot;]    response = llm.invoke([HumanMessage(content=user_input)])    return {&quot;answer&quot;: response.content}# æ„å»ºå›¾workflow = StateGraph(dict)workflow.add_node(&quot;answer&quot;, answer_question)workflow.add_edge(START, &quot;answer&quot;)workflow.add_edge(&quot;answer&quot;, END)graph = workflow.compile()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>è¿™ä¸ªå›¾ï¼š</p><ul><li>â€¢ æ¥æ”¶Â <strong>user_input</strong></li><li>â€¢ å°†å…¶å‘é€åˆ°Â <strong>GPT-4o</strong></li><li>â€¢ è¿”å› AI ç”Ÿæˆçš„å“åº”</li></ul><h3 id="_3-è®©å®ƒç”Ÿäº§å°±ç»ª" tabindex="-1"><a class="header-anchor" href="#_3-è®©å®ƒç”Ÿäº§å°±ç»ª"><span>3. è®©å®ƒç”Ÿäº§å°±ç»ª</span></a></h3><p>åœ¨å‘å…¨ä¸–ç•Œå¼€æ”¾ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ä¸ºçœŸå®ç”¨ä¾‹åŠ å›ºå®ƒã€‚</p><h4 id="é”™è¯¯å¤„ç†ä¸é‡è¯•" tabindex="-1"><a class="header-anchor" href="#é”™è¯¯å¤„ç†ä¸é‡è¯•"><span>é”™è¯¯å¤„ç†ä¸é‡è¯•</span></a></h4><p><strong>LLM APIs</strong>Â å¯èƒ½ä¼šå¤±è´¥æˆ–è¶…æ—¶ã€‚ç”¨Â <strong>try/except</strong>Â åŒ…è£…è°ƒç”¨ï¼š</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span>from tenacity import retry, wait_exponential, stop_after_attempt@retry(wait=wait_exponential(multiplier=1, min=2, max=10), stop=stop_after_attempt(3))def safe_invoke_llm(message):    return llm.invoke([HumanMessage(content=message)])def answer_question(state: dict) -&gt; dict:    user_input = state[&quot;user_input&quot;]    try:        response = safe_invoke_llm(user_input)        return {&quot;answer&quot;: response.content}    except Exception as e:        return {&quot;answer&quot;: f&quot;é”™è¯¯ï¼š{str(e)}&quot;}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="è¾“å…¥éªŒè¯" tabindex="-1"><a class="header-anchor" href="#è¾“å…¥éªŒè¯"><span>è¾“å…¥éªŒè¯</span></a></h4><p>æˆ‘ä»¬ä¸æƒ³è®©åˆ«äººå‘é€å·¨å¤§çš„æ•°æ®è´Ÿè½½ã€‚æ·»åŠ Â <strong>Pydantic</strong>Â çº¦æŸï¼š</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span>from pydantic import BaseModel, constrclass RequestData(BaseModel):    user_input: constr(min_length=1, max_length=500)  # é™åˆ¶è¾“å…¥å¤§å°</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="æ—¥å¿—è®°å½•" tabindex="-1"><a class="header-anchor" href="#æ—¥å¿—è®°å½•"><span>æ—¥å¿—è®°å½•</span></a></h4><p>æ·»åŠ æ—¥å¿—ä»¥æé«˜å¯è§æ€§ï¼š</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span>import logginglogging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)def answer_question(state: dict) -&gt; dict:    logger.info(f&quot;æ”¶åˆ°è¾“å…¥ï¼š{state[&#39;user_input&#39;]}&quot;)    response = safe_invoke_llm(state[&#39;user_input&#39;])    logger.info(&quot;å·²ç”Ÿæˆ LLM å“åº”&quot;)    return {&quot;answer&quot;: response.content}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="_4-ä½¿ç”¨-fastapi-æš´éœ²å·¥ä½œæµ" tabindex="-1"><a class="header-anchor" href="#_4-ä½¿ç”¨-fastapi-æš´éœ²å·¥ä½œæµ"><span>4. ä½¿ç”¨ FastAPI æš´éœ²å·¥ä½œæµ</span></a></h3><p>ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†è¿™ä¸ªå·¥ä½œæµå°è£…åœ¨Â <strong>FastAPI</strong>Â ä¸­ã€‚</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span># main.py</span></span>
<span class="line"><span></span></span>
<span class="line"><span>from fastapi import FastAPI</span></span>
<span class="line"><span>from workflow import graph, RequestData</span></span>
<span class="line"><span></span></span>
<span class="line"><span>app = FastAPI()@app.post(&quot;/run&quot;)</span></span>
<span class="line"><span>async def run_workflow(data: RequestData):</span></span>
<span class="line"><span>    result = graph.invoke({&quot;user_input&quot;: data.user_input})</span></span>
<span class="line"><span>        return {&quot;result&quot;: result[&quot;answer&quot;]}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>è¿è¡ŒæœåŠ¡å™¨ï¼š</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span>uvicorn main:app --reload</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="_5-æµ‹è¯•-api" tabindex="-1"><a class="header-anchor" href="#_5-æµ‹è¯•-api"><span>5. æµ‹è¯• API</span></a></h3><p>ä½ å¯ä»¥ä½¿ç”¨Â <strong>curl</strong>Â æµ‹è¯•ï¼š</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span>curl -X POST &quot;http://127.0.0.1:8000/run&quot; \\     -H &quot;Content-Type: application/json&quot; \\     -d &#39;{&quot;user_input&quot;:&quot;ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ&quot;}&#39;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>æˆ–è€…åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€Â <code>http://127.0.0.1:8000/docs</code>Â â€”â€”Â <strong>FastAPI</strong>Â ä¼šè‡ªåŠ¨ä¸ºä½ ç”ŸæˆÂ <strong>Swagger UI</strong>ï¼</p><figure><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/6Ex6Atic0gTyjGMgfE14oc2TGne0Vj2ibZRSicJpRgzcicS7pPoDtRjZFDx42sGRFxT7hJLnbIaGjTpZJknDLibMUFA/640?wx_fmt=webp&amp;from=appmsg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>è¿™ä¸ªäº¤äº’å¼ UI è®©ä½ ç›´æ¥åœ¨æµè§ˆå™¨ä¸­æµ‹è¯•ä½ çš„Â <strong>endpoint</strong>ã€‚</p><h3 id="_6-æ‰©å±•ä¸éƒ¨ç½²" tabindex="-1"><a class="header-anchor" href="#_6-æ‰©å±•ä¸éƒ¨ç½²"><span>6. æ‰©å±•ä¸éƒ¨ç½²</span></a></h3><p>ä¸ºç”Ÿäº§ç¯å¢ƒåšå‡†å¤‡çš„å‡ ä¸ªæ­¥éª¤ï¼š</p><ul><li>â€¢Â <strong>å¼‚æ­¥æ‰§è¡Œ</strong>ï¼š<strong>FastAPI</strong>Â æ˜¯å¼‚æ­¥åŸç”Ÿçš„ã€‚å¯¹äºå¤šä¸ª LLM è°ƒç”¨ï¼Œè®©å‡½æ•°å˜æˆå¼‚æ­¥çš„ã€‚</li><li>â€¢Â <strong>å·¥ä½œè¿›ç¨‹</strong>ï¼šä½¿ç”¨å¤šè¿›ç¨‹è¿è¡Œä»¥å®ç°å¹¶å‘ï¼š\`\`\`<br> uvicorn main:app --workers 4</li><li>â€¢Â <strong>Docker åŒ–</strong>ï¼š\`\`\`<br> FROM python:3.11-slimWORKDIR /appCOPY . .RUN pip install -r requirements.txtCMD [&quot;uvicorn&quot;, &quot;main:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]</li><li>â€¢Â <strong>è®¤è¯</strong>ï¼šä½¿ç”¨ API å¯†é’¥æˆ–Â <strong>JWT tokens</strong>Â æ¥ä¿æŠ¤Â <strong>endpoints</strong>ï¼ˆç¬¬äºŒéƒ¨åˆ†å³å°†æ¨å‡ºï¼‰ã€‚</li></ul><h3 id="_7-æ¶æ„æ¦‚è§ˆ" tabindex="-1"><a class="header-anchor" href="#_7-æ¶æ„æ¦‚è§ˆ"><span>7. æ¶æ„æ¦‚è§ˆ</span></a></h3><p>ä»¥ä¸‹æ˜¯æ•´ä½“è¿æ¥æ–¹å¼ï¼š</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span>POST /run</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Client</span></span>
<span class="line"><span></span></span>
<span class="line"><span>FastAPI</span></span>
<span class="line"><span></span></span>
<span class="line"><span>LangGraph</span></span>
<span class="line"><span></span></span>
<span class="line"><span>OpenAI\\_API</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Response</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>è¿™ä¸ªç®€å•çš„æ¶æ„è®©ä½ å¯ä»¥å°†ä»»ä½•Â <strong>LangGraph</strong>Â å˜æˆä¸€ä¸ªÂ <strong>API</strong>ã€‚</p><h2 id="_8-ç»“è®º" tabindex="-1"><a class="header-anchor" href="#_8-ç»“è®º"><span>8. ç»“è®º</span></a></h2><p>é€šè¿‡å‡ ä¸ªç®€å•çš„æ­¥éª¤ï¼Œæˆ‘ä»¬ï¼š</p><ul><li>â€¢ æ„å»ºäº†ä¸€ä¸ªÂ <strong>LangGraph</strong>Â å·¥ä½œæµ</li><li>â€¢ ä½¿ç”¨Â <strong>FastAPI</strong>Â å°†å…¶æš´éœ²ä¸ºÂ <strong>REST API</strong></li><li>â€¢ æ·»åŠ äº†ç”Ÿäº§å°±ç»ªçš„åŠŸèƒ½ï¼ˆéªŒè¯ã€é‡è¯•ã€æ—¥å¿—ï¼‰</li><li>â€¢ ä¸ºå¯æ‰©å±•çš„ AI å¾®æœåŠ¡å¥ å®šäº†åŸºç¡€</li></ul><p>è¿™ä¸ªè®¾ç½®å¯ä»¥æ”¯æŒä»èŠå¤©æœºå™¨äººåˆ°æ–‡æ¡£å¤„ç†å™¨å†åˆ° AI SaaS äº§å“çš„å„ç§åº”ç”¨ã€‚</p><h2 id="ä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆ" tabindex="-1"><a class="header-anchor" href="#ä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆ"><span>ä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆï¼Ÿ</span></a></h2><p>æˆ‘è®¡åˆ’æ¨å‡ºæœ¬æ•™ç¨‹çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œä½†æˆ‘æƒ³å¬å¬ä½ çš„æ„è§ã€‚</p><p>ğŸ‘‰ ä½ å¸Œæœ›æˆ‘æ¥ä¸‹æ¥è®²å“ªä¸€ä¸ªï¼Ÿ</p><ul><li>â€¢ æµå¼å“åº”ï¼ˆå®æ—¶èŠå¤©ï¼‰</li><li>â€¢ è®¤è¯ä¸å®‰å…¨æ€§</li><li>â€¢Â <strong>Docker</strong>Â ä¸äº‘éƒ¨ç½²</li><li>â€¢ é”™è¯¯ç›‘æ§ä¸å¯è§‚å¯Ÿæ€§</li></ul><p>åœ¨ä¸‹æ–¹è¯„è®ºä½ çš„é€‰æ‹©ï¼</p>`,58)])])}const d=s(t,[["render",r]]),g=JSON.parse('{"path":"/tld/pydeep/FastAPI-LangGraph.html","title":"FastAPI + LangGraphæ­å»º AI å·¥ä½œæµ","lang":"zh-CN","frontmatter":{"description":"FastAPI + LangGraphæ­å»º AI å·¥ä½œæµ AIå¤§æ¨¡å‹è§‚å¯Ÿç«™** æŸ¥çœ‹åŸæ–‡ ä½œè€… AIç ”ç©¶ç”Ÿ AIå¤§æ¨¡å‹è§‚å¯Ÿç«™ Large Language Models (LLMs) æ“…é•¿æ¨ç†ï¼Œä½†ç°å®ä¸–ç•Œçš„åº”ç”¨å¾€å¾€éœ€è¦æœ‰çŠ¶æ€ã€å¤šæ­¥éª¤çš„å·¥ä½œæµã€‚è¿™å°±æ˜¯ LangGraph çš„ç”¨æ­¦ä¹‹åœ°â€”â€”å®ƒè®©ä½ å¯ä»¥é€šè¿‡ç”± LLM é©±åŠ¨çš„èŠ‚ç‚¹å›¾æ¥æ„å»ºæ™ºèƒ½å·¥ä½œæµã€‚ ä½†å¦‚æœä½ æƒ³æŠŠ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"FastAPI + LangGraphæ­å»º AI å·¥ä½œæµ\\",\\"image\\":[\\"https://mmbiz.qpic.cn/sz_mmbiz_jpg/6Ex6Atic0gTyjGMgfE14oc2TGne0Vj2ibZQK9udtCtZDlo9JB2iaU81DNXJicyjWMbNHibmH2PxFPz6ya53GnB5hyTA/640?wx_fmt=webp&from=appmsg\\",\\"https://mmbiz.qpic.cn/sz_mmbiz_jpg/6Ex6Atic0gTyjGMgfE14oc2TGne0Vj2ibZRSicJpRgzcicS7pPoDtRjZFDx42sGRFxT7hJLnbIaGjTpZJknDLibMUFA/640?wx_fmt=webp&from=appmsg\\"],\\"dateModified\\":\\"2025-11-28T09:55:00.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"SecCMD\\",\\"url\\":\\"https://www.seccmd.net\\"}]}"],["meta",{"property":"og:url","content":"https://www.seccmd.net/tld/pydeep/FastAPI-LangGraph.html"}],["meta",{"property":"og:site_name","content":"æ˜å‰‘å®éªŒå®¤"}],["meta",{"property":"og:title","content":"FastAPI + LangGraphæ­å»º AI å·¥ä½œæµ"}],["meta",{"property":"og:description","content":"FastAPI + LangGraphæ­å»º AI å·¥ä½œæµ AIå¤§æ¨¡å‹è§‚å¯Ÿç«™** æŸ¥çœ‹åŸæ–‡ ä½œè€… AIç ”ç©¶ç”Ÿ AIå¤§æ¨¡å‹è§‚å¯Ÿç«™ Large Language Models (LLMs) æ“…é•¿æ¨ç†ï¼Œä½†ç°å®ä¸–ç•Œçš„åº”ç”¨å¾€å¾€éœ€è¦æœ‰çŠ¶æ€ã€å¤šæ­¥éª¤çš„å·¥ä½œæµã€‚è¿™å°±æ˜¯ LangGraph çš„ç”¨æ­¦ä¹‹åœ°â€”â€”å®ƒè®©ä½ å¯ä»¥é€šè¿‡ç”± LLM é©±åŠ¨çš„èŠ‚ç‚¹å›¾æ¥æ„å»ºæ™ºèƒ½å·¥ä½œæµã€‚ ä½†å¦‚æœä½ æƒ³æŠŠ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://mmbiz.qpic.cn/sz_mmbiz_jpg/6Ex6Atic0gTyjGMgfE14oc2TGne0Vj2ibZQK9udtCtZDlo9JB2iaU81DNXJicyjWMbNHibmH2PxFPz6ya53GnB5hyTA/640?wx_fmt=webp&from=appmsg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-11-28T09:55:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-11-28T09:55:00.000Z"}]]},"git":{"createdTime":1764323700000,"updatedTime":1764323700000,"contributors":[{"name":"fireadm","username":"fireadm","email":"iwanwu@hotmail.com","commits":1,"url":"https://github.com/fireadm"}]},"readingTime":{"minutes":3.8,"words":1139},"filePathRelative":"tld/pydeep/FastAPI-LangGraph.md","autoDesc":true}');export{d as comp,g as data};
