import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as l,f as e,o as d}from"./app-BywchsBJ.js";const r={};function o(m,t){return d(),l("div",null,[...t[0]||(t[0]=[e('<h1 id="ollama" tabindex="-1"><a class="header-anchor" href="#ollama"><span>Ollama</span></a></h1><h2 id="本地部署大模型-ollama" tabindex="-1"><a class="header-anchor" href="#本地部署大模型-ollama"><span>本地部署大模型 Ollama</span></a></h2><ul><li><a href="https://ollama.fan/getting-started/" target="_blank" rel="noopener noreferrer">https://ollama.fan/getting-started/</a></li><li>官网快捷下载安装 <a href="https://ollama.com/" target="_blank" rel="noopener noreferrer">https://ollama.com/</a></li><li>安装模型，执行命令 ollama run llama3</li></ul><h2 id="ollama-中文微调" tabindex="-1"><a class="header-anchor" href="#ollama-中文微调"><span>Ollama 中文微调</span></a></h2><ul><li>直接下载别人微调好的中文版<a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">https://huggingface.co/</a></li><li>导入微调后的模型，具体步骤todo</li></ul><h2 id="ollama使用指南【超全版】" tabindex="-1"><a class="header-anchor" href="#ollama使用指南【超全版】"><span>Ollama使用指南【超全版】</span></a></h2><p><a href="https://zhuanlan.zhihu.com/p/704951717" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/704951717</a></p><h2 id="功能设计" tabindex="-1"><a class="header-anchor" href="#功能设计"><span>功能设计</span></a></h2><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>功能</td><td>备注</td><td>笔记化</td><td>产品化</td></tr><tr><td>命令注入</td><td></td><td></td><td></td></tr><tr><td>py代码后门</td><td></td><td></td><td></td></tr><tr><td>配置安全</td><td></td><td></td><td></td></tr><tr><td>ollama 密钥？</td><td>.ollama/id_ed25519</td><td></td><td></td></tr><tr><td>ollama 日志</td><td>.ollama/logs/server.log</td><td></td><td></td></tr><tr><td>ollama history 历史记录</td><td>.ollama/history</td><td></td><td></td></tr><tr><td>ollama 模型配置</td><td>.ollama/models/manifests/registry.ollama.ai/library/llama3/latest</td><td></td><td></td></tr><tr><td>md5 篡改替换 shasum -a 256</td><td>模型文件 .ollama/models/blobs/ MacOS: ~/.ollama/models Linux: /usr/share/ollama/.ollama/models Windows: C:\\Users\\username.ollama\\models</td><td></td><td></td></tr><tr><td>ollama二进制文件</td><td>sudo chmod +x /usr/bin/ollama</td><td></td><td></td></tr><tr><td>ollama 端口</td><td>curl <a href="http://localhost:11434/" target="_blank" rel="noopener noreferrer">http://localhost:11434/</a></td><td></td><td></td></tr><tr><td>ollama API 安全</td><td>/api/generate</td><td></td><td></td></tr><tr><td>环境变量</td><td>OLLAMA_HOST OLLAMA_MODELS OLLAMA_ORIGINS OLLAMA_LLM_LIBRARY OLLAMA_DEBUG</td><td></td><td></td></tr></tbody></table>',9)])])}const h=a(r,[["render",o]]),i=JSON.parse('{"path":"/tld/ailab/ollama.html","title":"Ollama","lang":"zh-CN","frontmatter":{"description":"Ollama 本地部署大模型 Ollama https://ollama.fan/getting-started/ 官网快捷下载安装 https://ollama.com/ 安装模型，执行命令 ollama run llama3 Ollama 中文微调 直接下载别人微调好的中文版https://huggingface.co/ 导入微调后的模型，具体步骤...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Ollama\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-22T13:54:52.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"SecCMD\\",\\"url\\":\\"https://www.seccmd.net\\"}]}"],["meta",{"property":"og:url","content":"https://www.seccmd.net/tld/ailab/ollama.html"}],["meta",{"property":"og:site_name","content":"明剑实验室"}],["meta",{"property":"og:title","content":"Ollama"}],["meta",{"property":"og:description","content":"Ollama 本地部署大模型 Ollama https://ollama.fan/getting-started/ 官网快捷下载安装 https://ollama.com/ 安装模型，执行命令 ollama run llama3 Ollama 中文微调 直接下载别人微调好的中文版https://huggingface.co/ 导入微调后的模型，具体步骤..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-09-22T13:54:52.000Z"}],["meta",{"property":"article:modified_time","content":"2025-09-22T13:54:52.000Z"}]]},"git":{"createdTime":1758549292000,"updatedTime":1758549292000,"contributors":[{"name":"fireadm","username":"fireadm","email":"iwanwu@hotmail.com","commits":1,"url":"https://github.com/fireadm"}]},"readingTime":{"minutes":0.63,"words":190},"filePathRelative":"tld/ailab/ollama.md","autoDesc":true}');export{h as comp,i as data};
